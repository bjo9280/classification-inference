{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:19.420842Z",
     "start_time": "2019-01-23T05:03:16.821648Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function,division,absolute_import\n",
    "\n",
    "from traceback import print_exc\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:19.440976Z",
     "start_time": "2019-01-23T05:03:19.425234Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습당시 모델 설정치들\n",
    "\n",
    "_model_name = 'vgg_16'\n",
    "_input_name = 'input'\n",
    "_image_size = 224\n",
    "_dataset_num_classes = 2 # len(class_names)\n",
    "_preprocessing_name = 'vgg_16'\n",
    "_feature_endpoint = 'vgg_16/fc7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:34.324365Z",
     "start_time": "2019-01-23T05:03:34.293335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'save/model.ckpt-1000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불러올 학습모델\n",
    "\n",
    "input_checkpoint = 'save/model.ckpt-1000'\n",
    "#input_checkpoint = './0214/save/model.ckpt-100000'\n",
    "#input_checkpoint = './22re-vgg16/data/save/model.ckpt-70000'\n",
    "input_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 읽어오는 함수\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def read_image(im_path,flags=cv2.IMREAD_UNCHANGED):\n",
    "    if im_path.endswith('.npy'):\n",
    "        im = np.load(im_path)\n",
    "    else:\n",
    "        with open(im_path,'rb') as f:\n",
    "            im_encoded = f.read()\n",
    "        im = cv2.imdecode(np.frombuffer(im_encoded,dtype=np.uint8),flags=flags)\n",
    "        if len(im.shape) > 2:\n",
    "            im = im[:,:,::-1]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:20.806523Z",
     "start_time": "2019-01-23T05:03:20.797544Z"
    }
   },
   "outputs": [],
   "source": [
    "# VDL_InferenceProxy3 경로 설정\n",
    "\n",
    "#_libpath = os.path.expanduser('C:\\\\Program Files\\\\VDLServer\\\\VDL_InferenceProxy3\\\\engines\\\\tf\\\\lib')\n",
    "_libpath = os.path.expanduser('../')\n",
    "_slimpath = os.path.join(_libpath,'slim')\n",
    "sys.path.insert(0,_slimpath)\n",
    "sys.path.insert(0,_libpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:33.676145Z",
     "start_time": "2019-01-23T05:03:20.811601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 모델 구성\n",
    "\n",
    "from nets.nets_factory import get_network_fn\n",
    "\n",
    "\n",
    "network_fn = get_network_fn(\n",
    "    _model_name,\n",
    "    num_classes=_dataset_num_classes,\n",
    "    is_training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../slim/preprocessing/vgg_preprocessing.py:249: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf1.13/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From ../slim/preprocessing/vgg_preprocessing.py:256: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'vgg_16/fc8/squeezed:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서플로우 내부 이미지 전처리 구성\n",
    "\n",
    "from slim.preprocessing.preprocessing_factory import get_preprocessing\n",
    "\n",
    "\n",
    "preprocessing_fn = get_preprocessing(_preprocessing_name,is_training=False)\n",
    "\n",
    "image_input = tf.placeholder(name=_input_name,shape=[None,None,3],dtype=tf.uint8)\n",
    "preprocessed = preprocessing_fn(image_input, _image_size, _image_size)\n",
    "logits, endpoint = network_fn(tf.expand_dims(preprocessed,axis=0))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:36.804981Z",
     "start_time": "2019-01-23T05:03:34.326665Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tf1.13/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from save/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "# 세션 생성 및 학습모델 로딩\n",
    "\n",
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, input_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/home/joban/Gitrepo/projects/cathod_project_cls\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"input:0\"\n",
       "dtype: DT_UINT8\n",
       "tensor_shape {\n",
       "  dim {\n",
       "    size: -1\n",
       "  }\n",
       "  dim {\n",
       "    size: -1\n",
       "  }\n",
       "  dim {\n",
       "    size: 3\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.utils.build_tensor_info(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_3:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"Softmax_1:0\"\n",
       "dtype: DT_FLOAT\n",
       "tensor_shape {\n",
       "  dim {\n",
       "    size: 1\n",
       "  }\n",
       "  dim {\n",
       "    size: 2\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.utils.build_tensor_info(tf.nn.softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model.ckpt-1000\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./saved/1/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./saved/1/saved_model.pb'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -r ./saved/\n",
    "saved_model_path = './saved/1'\n",
    "\"\"\"Writes SavedModel to disk.\n",
    "  Args:\n",
    "    saved_model_path: Path to write SavedModel.\n",
    "    trained_checkpoint_prefix: path to trained_checkpoint_prefix.\n",
    "    inputs: The input image tensor to use for detection.\n",
    "    outputs: A tensor dictionary containing the outputs of a DetectionModel.\n",
    "  \"\"\"\n",
    "\n",
    "saver.restore(sess, input_checkpoint)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
    "\n",
    "tensor_info_inputs = {\n",
    "          'inputs': tf.saved_model.utils.build_tensor_info(image_input)}\n",
    "tensor_info_outputs = {\n",
    "    'scores' : tf.saved_model.utils.build_tensor_info(tf.nn.softmax(logits))\n",
    "}\n",
    "\n",
    "#for k, v in outputs.items():\n",
    "#    tensor_info_outputs[k] = tf.saved_model.utils.build_tensor_info(v)\n",
    "#tensor_info_outputs = tf.saved_model.utils.build_tensor_info(logits)\n",
    "\n",
    "detection_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "              inputs=tensor_info_inputs,\n",
    "              outputs=tensor_info_outputs,\n",
    "        method_name=signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "builder.add_meta_graph_and_variables(\n",
    "          sess, [tf.saved_model.tag_constants.SERVING],\n",
    "          signature_def_map={\n",
    "              signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "                  detection_signature,\n",
    "          },\n",
    "      )\n",
    "# builder.add_meta_graph_and_variables(\n",
    "#           sess, [tf.saved_model.tag_constants.SERVING],\n",
    "#           signature_def_map={\n",
    "#                'predict_images':\n",
    "#               detection_signature\n",
    "#           },\n",
    "#       )\n",
    "\n",
    "builder.save()\n",
    "\n",
    "\n",
    "\n",
    "# inp = graph.get_tensor_by_name('import/'+input_name + ':0')\n",
    "# out = graph.get_tensor_by_name('import/'+output_name + ':0')\n",
    "    \n",
    "    \n",
    "# sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
    "#         tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "#             {\"in\": input_tensor}, {\"out\": output_tensor})\n",
    "\n",
    "# builder.add_meta_graph_and_variables(sess,\n",
    "#                                          [tag_constants.SERVING],\n",
    "#                                          signature_def_map=sigs)\n",
    "\n",
    "# builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./saved/ /tmp/my_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['inputs'] tensor_info:\r\n",
      "        dtype: DT_UINT8\r\n",
      "        shape: (-1, -1, 3)\r\n",
      "        name: input:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (1, 2)\r\n",
      "        name: Softmax_2:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ./saved/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict_images']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['images'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: ParseExample/ParseExample:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 5)\n",
      "        name: index_to_string_Lookup:0\n",
      "    outputs['scores'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: TopKV2:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: unknown_rank\n",
      "        name: tf_example:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 5)\n",
      "        name: index_to_string_Lookup:0\n",
      "    outputs['scores'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: TopKV2:0\n",
      "  Method name is: tensorflow/serving/classify\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ~/SERVING_INCEPTION/SERVING_INCEPTION/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['predict_images']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['images'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 784)\r\n",
      "        name: x:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: y:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['inputs'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: unknown_rank\r\n",
      "        name: tf_example:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: index_to_string_Lookup:0\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: TopKV2:0\r\n",
      "  Method name is: tensorflow/serving/classify\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir /tmp/mnist_model/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['predict_images']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['images'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 784)\r\n",
      "        name: x:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: y:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir /tmp/mnist_t/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['predict']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['image_bytes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: input_tensor:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1)\r\n",
      "        name: ArgMax:0\r\n",
      "    outputs['probabilities'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 1001)\r\n",
      "        name: softmax_tensor:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['image_bytes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: input_tensor:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1)\r\n",
      "        name: ArgMax:0\r\n",
      "    outputs['probabilities'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 1001)\r\n",
      "        name: softmax_tensor:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir /tmp/resnet/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:03:36.814879Z",
     "start_time": "2019-01-23T05:03:36.808187Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(im_name,preproc_fn=None):\n",
    "#     im = read_image(im_name)\n",
    "#     if callable(preproc_fn):\n",
    "#         im = preproc_fn(im)\n",
    "#     im = np.tile(im[:,:,np.newaxis],[1,1,3]) # GRAY 에서 RGB 포맷으로 변환\n",
    "    preds_, = sess.run([logits], {image_input: im_name})\n",
    "    #print(preds_)\n",
    "    y = np.argmax(preds_[0])\n",
    "    score = tf.nn.softmax(preds_[0])[y]\n",
    "    return y, score, preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T05:05:05.497133Z",
     "start_time": "2019-01-23T05:03:39.336065Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t/0/0022_1.jpg 0\n",
      "t/0/0022_2.jpg 0\n",
      "t/0/0022_3.jpg 0\n",
      "t/0/0022_4.jpg 0\n",
      "t/0/0029_1.jpg 0\n",
      "t/0/0029_2.jpg 0\n",
      "t/0/0029_3.jpg 0\n",
      "t/0/0029_4.jpg 0\n",
      "t/0/0036_1.jpg 0\n",
      "t/0/0036_2.jpg 0\n",
      "t/0/0036_3.jpg 0\n",
      "t/0/0043_1.jpg 0\n",
      "t/0/0043_3.jpg 0\n",
      "t/0/0043_4.jpg 0\n",
      "t/0/0050_1.jpg 0\n",
      "t/0/0050_2.jpg 0\n",
      "t/0/0050_3.jpg 0\n",
      "t/0/0050_4.jpg 0\n",
      "t/0/0057_1.jpg 0\n",
      "t/0/0057_2.jpg 1\n",
      "t/0/0057_3.jpg 0\n",
      "t/0/0057_4.jpg 0\n",
      "t/0/0064_1.jpg 0\n",
      "t/0/0064_2.jpg 0\n",
      "t/0/0064_3.jpg 0\n",
      "t/0/0071_1.jpg 0\n",
      "t/0/0071_2.jpg 1\n",
      "t/0/0071_3.jpg 0\n",
      "t/0/0071_4.jpg 0\n",
      "t/0/0078_1.jpg 0\n",
      "t/0/0078_2.jpg 1\n",
      "t/0/0078_3.jpg 0\n",
      "t/0/0078_4.jpg 0\n",
      "t/0/0085_1.jpg 0\n",
      "t/0/0085_2.jpg 0\n",
      "t/0/0085_3.jpg 0\n",
      "t/0/0092_1.jpg 0\n",
      "t/0/0092_3.jpg 0\n",
      "t/0/0092_4.jpg 0\n",
      "t/0/0099_1.jpg 0\n",
      "t/0/0099_3.jpg 0\n",
      "t/0/0099_4.jpg 0\n",
      "t/0/0106_1.jpg 0\n",
      "t/0/0106_2.jpg 0\n",
      "t/0/0106_4.jpg 0\n",
      "t/1/101_48EA.jpg 1\n",
      "t/1/111_48EA.jpg 1\n",
      "t/1/113_48EA.jpg 1\n",
      "t/1/115_48EA.jpg 1\n",
      "t/1/122_48EA.jpg 1\n",
      "t/1/134_1EA.jpg 1\n",
      "t/1/167_48EA.jpg 1\n",
      "t/1/169_48EA.jpg 1\n",
      "t/1/171_48EA.jpg 1\n",
      "t/1/188_48EA.jpg 1\n",
      "t/1/190_48EA.jpg 1\n",
      "t/1/197_48EA.jpg 1\n",
      "t/1/199_48EA.jpg 1\n",
      "t/1/202_48EA.jpg 1\n",
      "t/1/204_48EA.jpg 1\n",
      "t/1/206_3EA.jpg 1\n",
      "t/1/206_48EA.jpg 1\n",
      "t/1/218_48EA.jpg 1\n",
      "t/1/251_48EA.jpg 1\n",
      "t/1/255_48EA.jpg 1\n",
      "t/1/349_48EA.jpg 1\n",
      "t/1/351_48EA.jpg 1\n",
      "t/1/353_48EA.jpg 1\n",
      "t/1/356_48EA.jpg 1\n",
      "t/1/360_48EA.jpg 1\n",
      "t/1/365_4EA.jpg 1\n",
      "t/1/400.jpg 1\n",
      "t/1/419.jpg 1\n",
      "t/1/421.jpg 1\n",
      "t/1/423.jpg 1\n",
      "t/1/456_3EA.jpg 1\n",
      "t/1/479.jpg 0\n",
      "t/1/510.jpg 1\n",
      "t/1/512.jpg 1\n",
      "t/1/512_4EA.jpg 1\n",
      "t/1/514.jpg 1\n",
      "t/1/514_4EA.jpg 1\n",
      "t/1/52_4EA.jpg 1\n",
      "t/1/575.jpg 1\n",
      "t/1/577.jpg 1\n",
      "t/1/69_48EA.jpg 1\n",
      "t/1/76_48EA.jpg 1\n",
      "t/1/78_48EA.jpg 1\n",
      "t/1/80_48EA.jpg 1\n",
      "t/1/99_48EA.jpg 1\n"
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from imutils import paths\n",
    "\n",
    "path = 't'\n",
    "testPaths = sorted(list(paths.list_images(path)))\n",
    "\n",
    "gt = []\n",
    "y_pred = []\n",
    "\n",
    "for path in testPaths:\n",
    "    im = read_image(path, flags=cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    y, score, y_pred = predict(im)\n",
    "    #y_pred.append(y)\n",
    "    gt.append(path.split('/')[-2])\n",
    "    print(path, y)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[37  8]\n",
      " [ 0 45]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        45\n",
      "           1       0.85      1.00      0.92        45\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        90\n",
      "   macro avg       0.92      0.91      0.91        90\n",
      "weighted avg       0.92      0.91      0.91        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gt = list(map(int, gt))\n",
    "    \n",
    "confusion = confusion_matrix(gt, y_pred)\n",
    "print('confusion matrix:')\n",
    "print(confusion)\n",
    "report = classification_report(gt, y_pred, output_dict=False)\n",
    "print('classification_report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
